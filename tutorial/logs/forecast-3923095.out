
Lmod is automatically replacing "gcc-native/14.2" with "gcc/12.2.0".


The following have been reloaded with a version change:
  1) cray-libsci/24.11.0 => cray-libsci/23.09.1.1
  2) cray-mpich/8.1.31 => cray-mpich/8.1.27
  3) libfabric/1.22.0 => libfabric/1.20.1

Job configuration:
  ERA5_DIR      = /lustre/orion/lrn036/world-shared/ERA5_npz/1.40625_deg/
  FORECAST_TYPE = direct
  MODEL         = res_slimvit
  PRED_RANGE    = 120
  MAX_EPOCHS    = 5
  PATIENCE      = 5
  OUTPUT_DIR    = /lustre/orion/csc662/proj-shared/janet/forecasting
  CHECKPOINT    = /lustre/orion/csc662/proj-shared/janet/forecasting/v2_baseline_test_high_ressolution_res_slimvit_direct_forecasting_120/checkpoints/last.ckpt
Loading model: res_slimvit
Loading optimizer adamw
Loading learning rate scheduler: linear-warmup-cosine-annealing
Loading training loss: lat_mse
No train transform
Loading validation loss: lat_rmse
Loading validation loss: lat_acc
Loading validation loss: lat_mse
Loading validation transform: denormalize
Loading validation transform: denormalize
No validation transform
Loading test loss: lat_rmse
Loading test loss: lat_acc
Loading test transform: denormalize
Loading test transform: denormalize
[rank: 0] Seed set to 0
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/lightning_fabric/strategies/fsdp.py:697: `FSDPStrategy(activation_checkpointing=<class 'timm.models.vision_transformer.Block'>)` is deprecated, use `FSDPStrategy(activation_checkpointing_policy={<class 'timm.models.vision_transformer.Block'>})` instead.
Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
Traceback (most recent call last):
  File "/autofs/nccs-svm1_home2/janetw/diffusion/ORBIT-2-sandbox/tutorial/./era5_era5_test.py", line 754, in <module>
    model = cl.LitModule.load_from_checkpoint(
        args.checkpoint,
    ...<6 lines>...
        test_target_tranfsorms=model.test_target_transforms,
    )
  File "/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/pytorch_lightning/utilities/model_helpers.py", line 125, in wrapper
    return self.method(cls, *args, **kwargs)
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/pytorch_lightning/core/module.py", line 1662, in load_from_checkpoint
    loaded = _load_from_checkpoint(
        cls,
    ...<4 lines>...
        **kwargs,
    )
  File "/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/pytorch_lightning/core/saving.py", line 91, in _load_from_checkpoint
    model = _load_state(cls, checkpoint, strict=strict, **kwargs)
  File "/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/pytorch_lightning/core/saving.py", line 187, in _load_state
    keys = obj.load_state_dict(checkpoint["state_dict"], strict=strict)  # type: ignore[arg-type]
  File "/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/torch/nn/modules/module.py", line 2624, in load_state_dict
    raise RuntimeError(
    ...<3 lines>...
    )
RuntimeError: Error(s) in loading state_dict for LitModule:
	size mismatch for net.patch_embed.proj.weight: copying a param with shape torch.Size([128, 10, 8, 8]) from checkpoint, the shape in current model is torch.Size([128, 11, 8, 8]).
	size mismatch for net.path2.0.weight: copying a param with shape torch.Size([4, 10, 3, 3]) from checkpoint, the shape in current model is torch.Size([4, 11, 3, 3]).
	size mismatch for net.path2.3.weight: copying a param with shape torch.Size([2, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 4, 3, 3]).
	size mismatch for net.path2.3.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).
	size mismatch for net.path1.0.weight: copying a param with shape torch.Size([4, 2, 3, 3]) from checkpoint, the shape in current model is torch.Size([4, 1, 3, 3]).
	size mismatch for net.path1.3.weight: copying a param with shape torch.Size([2, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 4, 3, 3]).
	size mismatch for net.path1.3.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).
	size mismatch for net.to_img.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 128]).
	size mismatch for net.to_img.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
srun: error: frontier03809: task 0: Exited with exit code 1
srun: Terminating StepId=3923095.0

real	0m25.866s
user	0m0.018s
sys	0m0.031s
