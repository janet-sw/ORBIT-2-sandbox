
Lmod is automatically replacing "gcc-native/14.2" with "gcc/12.2.0".


The following have been reloaded with a version change:
  1) cray-libsci/24.11.0 => cray-libsci/23.09.1.1
  2) cray-mpich/8.1.31 => cray-mpich/8.1.27
  3) libfabric/1.22.0 => libfabric/1.20.1

Job configuration:
  ERA5_DIR      = /lustre/orion/lrn036/world-shared/ERA5_npz/1.40625_deg/
  FORECAST_TYPE = direct
  MODEL         = res_slimvit
  PRED_RANGE    = 120
  MAX_EPOCHS    = 50
  PATIENCE      = 20
  OUTPUT_DIR    = /lustre/orion/csc662/proj-shared/janet/forecasting
  CHECKPOINT    = 
world_size 8 num_nodes 1
[INFO] Using superres_factor=4 for LR 32x64 -> HR 128x256
Loading model: res_slimvit
Loading model: res_slimvit
Loading model: res_slimvit
Loading model: res_slimvit
Loading model: res_slimvit
Loading model: res_slimvit
Loading model: res_slimvit
Loading model: res_slimvit
Loading optimizer adamw
Loading optimizer adamw
Loading optimizer adamw
Loading optimizer adamw
Loading optimizer adamw
Loading optimizer adamw
Loading optimizer adamw
Loading optimizer adamw
Loading learning rate scheduler: linear-warmup-cosine-annealing
Loading learning rate scheduler: linear-warmup-cosine-annealing
Loading learning rate scheduler: linear-warmup-cosine-annealing
Loading learning rate scheduler: linear-warmup-cosine-annealing
Loading learning rate scheduler: linear-warmup-cosine-annealing
Loading learning rate scheduler: linear-warmup-cosine-annealing
Loading learning rate scheduler: linear-warmup-cosine-annealing
Loading learning rate scheduler: linear-warmup-cosine-annealing
Loading training loss: lat_mse
Loading training loss: lat_mse
Loading training loss: lat_mse
Loading training loss: lat_mse
Loading training loss: lat_mse
Loading training loss: lat_mse
Loading training loss: lat_mse
Loading training loss: lat_mse
No train transform
No train transform
No train transform
No train transform
No train transform
No train transform
No train transform
No train transform
Loading validation loss: lat_rmse
Loading validation loss: lat_rmse
Loading validation loss: lat_rmse
Loading validation loss: lat_rmse
Loading validation loss: lat_rmse
Loading validation loss: lat_rmse
Loading validation loss: lat_rmse
Loading validation loss: lat_rmse
Loading validation loss: lat_acc
Loading validation loss: lat_acc
Loading validation loss: lat_acc
Loading validation loss: lat_acc
Loading validation loss: lat_acc
Loading validation loss: lat_acc
Loading validation loss: lat_acc
Loading validation loss: lat_acc
Loading validation loss: lat_mse
Loading validation loss: lat_mse
Loading validation transform: denormalize
Loading validation transform: denormalize
Loading validation loss: lat_mse
Loading validation transform: denormalize
Loading validation loss: lat_mse
Loading validation transform: denormalize
Loading validation transform: denormalize
Loading validation loss: lat_mse
Loading validation loss: lat_mse
Loading validation transform: denormalize
Loading validation transform: denormalize
Loading validation transform: denormalize
No validation transform
Loading validation transform: denormalize
No validation transform
Loading validation transform: denormalize
No validation transform
Loading validation loss: lat_mse
No validation transform
Loading validation transform: denormalize
Loading validation transform: denormalize
Loading validation transform: denormalize
Loading validation loss: lat_mse
No validation transform
No validation transform
Loading validation transform: denormalize
Loading validation transform: denormalize
No validation transform
Loading validation transform: denormalize
No validation transform
Loading test loss: lat_rmse
Loading test loss: lat_rmse
Loading test loss: lat_rmse
Loading test loss: lat_rmse
Loading test loss: lat_rmse
Loading test loss: lat_rmse
Loading test loss: lat_rmse
Loading test loss: lat_rmse
Loading test loss: lat_acc
Loading test transform: denormalize
Loading test transform: denormalize
Loading test loss: lat_acc
Loading test transform: denormalize
Loading test transform: denormalize
Loading test loss: lat_acc
Loading test loss: lat_acc
Loading test transform: denormalize
Loading test loss: lat_acc
Loading test loss: lat_acc
Loading test transform: denormalize
Loading test loss: lat_acc
Loading test transform: denormalize
Loading test transform: denormalize
Loading test transform: denormalize
Loading test transform: denormalize
Loading test transform: denormalize
Loading test transform: denormalize
Loading test transform: denormalize
Loading test loss: lat_acc
Loading test transform: denormalize
Loading test transform: denormalize
Loading test transform: denormalize
[rank: 1] Seed set to 0
[rank: 2] Seed set to 0
[rank: 3] Seed set to 0
[rank: 5] Seed set to 0
[rank: 0] Seed set to 0
[rank: 4] Seed set to 0
[rank: 6] Seed set to 0
[rank: 7] Seed set to 0
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/lightning_fabric/strategies/fsdp.py:697: `FSDPStrategy(activation_checkpointing=<class 'timm.models.vision_transformer.Block'>)` is deprecated, use `FSDPStrategy(activation_checkpointing_policy={<class 'timm.models.vision_transformer.Block'>})` instead.
Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
>> Fresh run
>> Fresh run
>> Fresh run
>> Fresh run
>> Fresh run
>> Fresh run
>> Fresh run
>> Fresh run
You are using a CUDA device ('AMD Instinct MI250X') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8
Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8
Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8
Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8
Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8
[W1123 16:34:17.067048058 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [frontier02557.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 16:34:17.067407905 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [frontier02557.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 16:34:17.067529802 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [frontier02557.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 16:34:17.067611279 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [frontier02557.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 16:34:17.067701715 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [frontier02557.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 16:34:17.067733396 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [frontier02557.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 16:34:17.067777622 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [frontier02557.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 16:34:17.125198232 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [frontier02557.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 8 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.
┏━━━┳━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃   ┃ Name ┃ Type         ┃ Params ┃ Mode  ┃
┡━━━╇━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0 │ net  │ Res_Slim_ViT │  233 K │ train │
└───┴──────┴──────────────┴────────┴───────┘
Trainable params: 233 K                                                         
Non-trainable params: 0                                                         
Total params: 233 K                                                             
Total estimated model params size (MB): 0                                       
Modules in train mode: 208                                                      
Modules in eval mode: 0                                                         
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 7, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 7, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 7, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 7, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 7, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 7, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 7, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/lustre/orion/csc662/proj-shared/janet/miniconda3/envs/orbit/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 7, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Training: |          | 0/? [00:00<?, ?it/s]Training: |          | 0/? [00:00<?, ?it/s]Epoch 0: |          | 0/? [00:00<?, ?it/s] ======================================================================
ACTUAL TENSOR SHAPES IN TRAINING
======================================================================
Input (x) shape: torch.Size([128, 8, 32, 64])
Target (y) shape: torch.Size([128, 1, 128, 256])
Expected input: [batch, 26, 32, 64]
Expected target: [batch, 5, 128, 256]
======================================================================
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 0: |          | 20/? [00:40<00:00,  0.49it/s]Epoch 0: |          | 20/? [00:40<00:00,  0.49it/s, v_num=0, train/lat_mse:aggregate=0.709]Epoch 0: |          | 40/? [00:42<00:00,  0.94it/s, v_num=0, train/lat_mse:aggregate=0.709]Epoch 0: |          | 40/? [00:42<00:00,  0.94it/s, v_num=0, train/lat_mse:aggregate=0.685]Epoch 0: |          | 40/? [00:50<00:00,  0.79it/s, v_num=0, train/lat_mse:aggregate=0.692]Epoch 0: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.692]         Epoch 1: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.692][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 1: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.692]Epoch 1: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0971]Epoch 1: |          | 40/? [01:17<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0971]Epoch 1: |          | 40/? [01:17<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0689]Epoch 1: |          | 40/? [01:19<00:00,  0.50it/s, v_num=0, train/lat_mse:aggregate=0.0596]Epoch 1: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0596]         Epoch 2: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0596][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 2: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0596]Epoch 2: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0591]Epoch 2: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0591]Epoch 2: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0529]Epoch 2: |          | 40/? [01:19<00:00,  0.50it/s, v_num=0, train/lat_mse:aggregate=0.049] Epoch 2: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.049]         Epoch 3: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.049][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 3: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.049]Epoch 3: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0383]Epoch 3: |          | 40/? [01:19<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0383]Epoch 3: |          | 40/? [01:19<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0354]Epoch 3: |          | 40/? [01:20<00:00,  0.50it/s, v_num=0, train/lat_mse:aggregate=0.0331]Epoch 3: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0331]         Epoch 4: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0331][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 4: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0331]Epoch 4: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0301]Epoch 4: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0301]Epoch 4: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0296]Epoch 4: |          | 40/? [01:19<00:00,  0.50it/s, v_num=0, train/lat_mse:aggregate=0.028] Epoch 4: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.028]         Epoch 5: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.028][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 5: |          | 20/? [01:17<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.028]Epoch 5: |          | 20/? [01:17<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0248]Epoch 5: |          | 40/? [01:19<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0248]Epoch 5: |          | 40/? [01:19<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0239]Epoch 5: |          | 40/? [01:20<00:00,  0.50it/s, v_num=0, train/lat_mse:aggregate=0.0221]Epoch 5: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0221]         Epoch 6: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0221][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 6: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0221]Epoch 6: |          | 20/? [01:16<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0236]Epoch 6: |          | 40/? [01:17<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0236]Epoch 6: |          | 40/? [01:17<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0203]Epoch 6: |          | 40/? [01:19<00:00,  0.50it/s, v_num=0, train/lat_mse:aggregate=0.0187]Epoch 6: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0187]         Epoch 7: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0187][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 7: |          | 20/? [01:15<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0187]Epoch 7: |          | 20/? [01:15<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0198]Epoch 7: |          | 40/? [01:17<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0198]Epoch 7: |          | 40/? [01:17<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0198]Epoch 7: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0196]Epoch 7: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0196]         Epoch 8: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0196][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 8: |          | 20/? [01:14<00:00,  0.27it/s, v_num=0, train/lat_mse:aggregate=0.0196]Epoch 8: |          | 20/? [01:14<00:00,  0.27it/s, v_num=0, train/lat_mse:aggregate=0.0205]Epoch 8: |          | 40/? [01:16<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0205]Epoch 8: |          | 40/? [01:16<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0187]Epoch 8: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0183]Epoch 8: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0183]         Epoch 9: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0183][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 9: |          | 20/? [01:15<00:00,  0.27it/s, v_num=0, train/lat_mse:aggregate=0.0183]Epoch 9: |          | 20/? [01:15<00:00,  0.27it/s, v_num=0, train/lat_mse:aggregate=0.0192]Epoch 9: |          | 40/? [01:16<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0192]Epoch 9: |          | 40/? [01:16<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0184]Epoch 9: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0192]Epoch 9: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0192]         Epoch 10: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0192][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 10: |          | 20/? [01:15<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0192]Epoch 10: |          | 20/? [01:15<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0188]Epoch 10: |          | 40/? [01:17<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0188]Epoch 10: |          | 40/? [01:17<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0175]Epoch 10: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0183]Epoch 10: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0183]         Epoch 11: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0183][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 11: |          | 20/? [01:15<00:00,  0.27it/s, v_num=0, train/lat_mse:aggregate=0.0183]Epoch 11: |          | 20/? [01:15<00:00,  0.27it/s, v_num=0, train/lat_mse:aggregate=0.0182]Epoch 11: |          | 40/? [01:17<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0182]Epoch 11: |          | 40/? [01:17<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.017] Epoch 11: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.0173]Epoch 11: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0173]         Epoch 12: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.0173][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
Epoch 12: |          | 20/? [01:15<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0173]Epoch 12: |          | 20/? [01:15<00:00,  0.26it/s, v_num=0, train/lat_mse:aggregate=0.0165]Epoch 12: |          | 40/? [01:17<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.0165]Epoch 12: |          | 40/? [01:17<00:00,  0.52it/s, v_num=0, train/lat_mse:aggregate=0.020] Epoch 12: |          | 40/? [01:18<00:00,  0.51it/s, v_num=0, train/lat_mse:aggregate=0.019]Epoch 12: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.019]         Epoch 13: |          | 0/? [00:00<?, ?it/s, v_num=0, train/lat_mse:aggregate=0.019][COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
[COLLATE DEBUG] Input shape after resize: torch.Size([128, 8, 32, 64]), Target shape: torch.Size([128, 1, 128, 256])
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 3921809.0 ON frontier02557 CANCELLED AT 2025-11-23T16:54:11 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 3921809 ON frontier02557 CANCELLED AT 2025-11-23T16:54:11 DUE TO TIME LIMIT ***
[rank: 2] Received SIGTERM: 15
[rank: 5] Received SIGTERM: 15
[rank: 6] Received SIGTERM: 15
[rank: 0] Received SIGTERM: 15
[rank: 1] Received SIGTERM: 15
[rank: 4] Received SIGTERM: 15
[rank: 7] Received SIGTERM: 15
